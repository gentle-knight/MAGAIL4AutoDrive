# MAGAIL4AutoDrive

> åŸºäºå¤šæ™ºèƒ½ä½“ç”Ÿæˆå¯¹æŠ—æ¨¡ä»¿å­¦ä¹ (MAGAIL)çš„è‡ªåŠ¨é©¾é©¶è®­ç»ƒç³»ç»Ÿ | MetaDrive + Waymo Open Motion Dataset

æœ¬é¡¹ç›®åˆ©ç”¨ Waymo çœŸå®é©¾é©¶æ•°æ®ï¼Œé€šè¿‡ MetaDrive ä»¿çœŸç¯å¢ƒæ„å»ºä¸“å®¶å›æ”¾ç³»ç»Ÿï¼Œæå–è½¦è¾†çŠ¶æ€ä¸åŠ¨ä½œï¼Œç”¨äºè®­ç»ƒå¤šæ™ºèƒ½ä½“æ¨¡ä»¿å­¦ä¹ ç®—æ³• (MAGAIL)ã€‚

## ğŸ“ æ ¸å¿ƒæ¨¡å—

*   **`Env/expert_replay_env.py`**: ä¸“å®¶å›æ”¾ç¯å¢ƒã€‚æ ¸å¿ƒç±» `ExpertReplayEnv`ï¼Œè´Ÿè´£è¯»å– Waymo è½¨è¿¹ï¼Œè®¡ç®—é€†åŠ¨åŠ›å­¦åŠ¨ä½œï¼Œå¹¶è¿‡æ»¤éé“è·¯/é™æ€è½¦è¾†ã€‚
*   **`Env/inverse_dynamics.py`**: é€†åŠ¨åŠ›å­¦æ¨¡å—ã€‚æ ¹æ®è½¦è¾†ä½ç½®å’Œèˆªå‘è®¡ç®—æ²¹é—¨ã€åˆ¹è½¦å’Œè½¬å‘åŠ¨ä½œã€‚
*   **`scripts/generate_expert_data.py`**: æ•°æ®æ”¶é›†è„šæœ¬ã€‚æ‰¹é‡è¿è¡Œåœºæ™¯å¹¶ä¿å­˜è®­ç»ƒæ•°æ®ã€‚
*   **`scripts/visualize_replay.py`**: å¯è§†åŒ–è„šæœ¬ã€‚ç”¨äºè§‚å¯Ÿå›æ”¾æ•ˆæœå’Œæ•°æ®è´¨é‡ã€‚

***

## ğŸš€ 1. æ•°æ®æ”¶é›†

### ç”Ÿæˆä¸“å®¶æ•°æ®
ä½¿ç”¨ `generate_expert_data.py` è„šæœ¬ä» Waymo æ•°æ®é›†ä¸­æ‰¹é‡æå– (State, Action) å¯¹ã€‚

```bash
# è®¾ç½® Python è·¯å¾„
export PYTHONPATH=$PYTHONPATH:.:./metadrive

# è¿è¡Œç”Ÿæˆè„šæœ¬
# --data_dir: Waymo æ•°æ®è·¯å¾„ (å»ºè®®ä½¿ç”¨ exp_filtered)
# --output_dir: ç»“æœä¿å­˜è·¯å¾„
# --num_scenarios: è¦å¤„ç†çš„åœºæ™¯æ•°é‡
python scripts/generate_expert_data.py \
    --data_dir data/exp_filtered \
    --output_dir data/training_data \
    --num_scenarios 100 \
    --start_index 0
```

**ç”Ÿæˆçš„ `.pkl` æ–‡ä»¶ç»“æ„**ï¼š
åŒ…å«ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€æ¡è½¦è¾†è½¨è¿¹ï¼ˆTrajectory Dictionaryï¼‰ï¼š
*   `obs`: `(T, 45)` - è§‚æµ‹çŸ©é˜µã€‚åŒ…å« Ego çŠ¶æ€ (5ç»´) + 10è¾†é‚»å±…è½¦ç›¸å¯¹ä¿¡æ¯ (40ç»´)ã€‚
*   `acts`: `(T, 2)` - åŠ¨ä½œçŸ©é˜µã€‚`[Steering, Accel]`ï¼Œå½’ä¸€åŒ–åˆ° `[-1, 1]`ã€‚
*   `agent_id`: è½¦è¾† IDã€‚
*   `scenario_id`: æ‰€å±åœºæ™¯ IDã€‚

**å†…ç½®è¿‡æ»¤å™¨**ï¼š
è„šæœ¬ä¼šè‡ªåŠ¨è¿‡æ»¤æ‰ä»¥ä¸‹æ— æ•ˆè½¦è¾†ï¼š
1.  **éé“è·¯è½¦è¾†**ï¼šå§‹ç»ˆåœ¨åœè½¦åœºæˆ–è·¯å¤–è¡Œé©¶çš„è½¦è¾†ã€‚
2.  **é™æ€è½¦è¾†**ï¼šå…¨ç§°ç§»åŠ¨è·ç¦»å°äº 5ç±³ ä¸”é€Ÿåº¦ä»æœªè¶…è¿‡ 1m/s çš„è½¦è¾†ï¼ˆä½œä¸ºèƒŒæ™¯æµå­˜åœ¨ï¼Œä¸æ”¶é›†æ•°æ®ï¼‰ã€‚

---

## ğŸ” 2. æ•°æ®å¯è§†åŒ–ä¸éªŒè¯

### å›æ”¾å¯è§†åŒ–
ä½¿ç”¨ `visualize_replay.py` ç›´è§‚åœ°è§‚å¯Ÿå›æ”¾æ•ˆæœï¼Œç¡®è®¤è½¦è¾†è¡Œä¸ºæ˜¯å¦è‡ªç„¶ï¼Œä»¥åŠè¿‡æ»¤é€»è¾‘æ˜¯å¦ç”Ÿæ•ˆã€‚

```bash
# è¿è¡Œå¯è§†åŒ–
# --horizon: å›æ”¾çš„æœ€å¤§æ­¥æ•° (Waymo åœºæ™¯é€šå¸¸ä¸º 90 æˆ– 198 æ­¥)
python scripts/visualize_replay.py \
    --data_dir data/exp_filtered \
    --start_index 0 \
    --num_scenarios 1 \
    --horizon 200
```

**è§‚å¯Ÿè¦ç‚¹**ï¼š
*   **å—æ§è½¦è¾† (Controlled Agents)**ï¼šæ§åˆ¶å°ä¼šæ˜¾ç¤ºæ•°é‡ï¼ˆå¦‚ `Controlled agents: 2`ï¼‰ã€‚è¿™äº›æ˜¯çœŸæ­£äº§ç”Ÿæ•°æ®çš„è½¦è¾†ã€‚
*   **èƒŒæ™¯è½¦è¾†**ï¼šå¦‚æœåœ¨æ¸²æŸ“å›¾ä¸­çœ‹åˆ°å…¶ä»–è½¦ï¼ˆé€šå¸¸æ˜¯è·¯è¾¹åœæ”¾çš„ï¼‰ï¼Œä½†å—æ§æ•°é‡å¾ˆå°‘ï¼Œè¯´æ˜é™æ€è¿‡æ»¤ç”Ÿæ•ˆäº†ã€‚

### æ•°æ®åˆ†æ
ä½¿ç”¨ `analyze_expert_data.py` æŸ¥çœ‹ç”Ÿæˆæ•°æ®çš„ç»Ÿè®¡åˆ†å¸ƒã€‚

```bash
python scripts/analyze_expert_data.py --data_path data/training_data/expert_data_0_100.pkl
```

---

## ğŸ§  3. æ¨¡å‹è®­ç»ƒ (Next Steps)

æœ‰äº† `data/training_data/` ä¸‹çš„ä¸“å®¶æ•°æ®åï¼Œæ‚¨å¯ä»¥å¼€å§‹è®­ç»ƒ MAGAIL æ¨¡å‹ã€‚

### è®­ç»ƒæµç¨‹
1.  **åŠ è½½æ•°æ®**ï¼šä½¿ç”¨ `dataset/expert_dataset.py` ä¸­çš„ `ExpertDataset` ç±»åŠ è½½ `.pkl` æ•°æ®ã€‚
2.  **åˆå§‹åŒ– MAGAIL**ï¼š
    *   **Generator (Policy)**: æ¥æ”¶è§‚æµ‹ `(B, 45)`ï¼Œè¾“å‡ºåŠ¨ä½œ `(B, 2)`ã€‚
    *   **Discriminator**: æ¥æ”¶çŠ¶æ€-åŠ¨ä½œå¯¹ `(s, a)`ï¼Œåˆ¤æ–­æ˜¯ä¸“å®¶è¿˜æ˜¯ç”Ÿæˆå™¨ã€‚
3.  **äº¤äº’é‡‡æ ·**ï¼š
    *   åœ¨ `MultiAgentScenarioEnv`ï¼ˆéå›æ”¾æ¨¡å¼ï¼‰ä¸­è¿è¡Œ Policyã€‚
    *   æ”¶é›† Policy ç”Ÿæˆçš„è½¨è¿¹ã€‚
4.  **å¯¹æŠ—æ›´æ–°**ï¼š
    *   åˆ©ç”¨ä¸“å®¶æ•°æ®å’Œ Policy æ•°æ®è®­ç»ƒ Discriminatorã€‚
    *   åˆ©ç”¨ Discriminator çš„è¾“å‡ºä½œä¸º Reward (GAIL Reward) è®­ç»ƒ Policy (PPO/TRPO)ã€‚

### æ¨èé…ç½®
*   **Observation**: 45ç»´ (Ego + 10 Neighbors)
*   **Action**: 2ç»´ Continuous (Steering, Accel)
*   **Horizon**: 200 steps
*   **Batch Size**: 1024+ (å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸‹æ•°æ®é‡å¾ˆå¤§)
